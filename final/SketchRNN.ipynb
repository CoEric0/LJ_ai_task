{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 参数设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Config():\n",
    "    def __init__(self):\n",
    "        self.mode = 'train' # train or test\n",
    "\n",
    "        self.continue_train = False # 是否继续训练\n",
    "        self.last_train_epoch = 0 # 上次训练的epoch\n",
    "\n",
    "\n",
    "        # 数据的部分特征\n",
    "        self.data_lable = 'pig'\n",
    "        self.data_path = './sketch_datas/'\n",
    "        self.data_labels_list = ['ambulance','apple','bear','bicycle','bird','bus','cat','foot','owl','pig']\n",
    "        self.data_max = 5000 # 每个类别的最大数据量,节省训练时间\n",
    "        # self.full_length = 256 # 一条数据的完整长度\n",
    "        self.N_max = 0 # 一条数据的最大长度，可修改\n",
    "        self.lengths = [] # 一条数据的实际长度，可修改\n",
    "\n",
    "\n",
    "        # 编码器的参数设置\n",
    "        self.encoder_dim = 256 # encoder的输出维度\n",
    "        self.z_dim = 128 # 中间向量Z的维度\n",
    "\n",
    "        # 解码器的参数设置\n",
    "        self.decoder_dim = 512 # decoder的输出维度\n",
    "        self.M = 20 # GMM的分布数量\n",
    "\n",
    "        # 训练参数\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = 'cuda'\n",
    "        elif torch.backends.mps.is_available():\n",
    "            self.device = 'mps'\n",
    "        else:\n",
    "            self.device = 'cpu'\n",
    "\n",
    "        self.grad_clip = 1.0 # 梯度裁剪\n",
    "        self.batch_size = 111\n",
    "        self.lr = 0.001\n",
    "        self.epoch = 50 # 本次训练的epoch\n",
    "        self.W_kl = 0.5 # kl损失的权重\n",
    "        self.temperature = 0.0001 #温度参数\n",
    "\n",
    "\n",
    "        # 测试参数\n",
    "        self.test_epoch = self.epoch\n",
    "        self.gen_num = 10 # 生成的数据数量\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 数据\n",
    "读入数据，并对数据进行预处理\n",
    "数据集由配置文件决定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from re import split\n",
    "\n",
    "def get_max(arr):\n",
    "    return arr.shape[1]\n",
    "    \n",
    "\n",
    "# 按照ratios划分数据集\n",
    "def split_data(arr, ratios):\n",
    "    # 计算分割点\n",
    "    total_length = arr.shape[0]\n",
    "    splits = [int(total_length * ratio / sum(ratios)) for ratio in ratios]\n",
    "    \n",
    "    splits[-1] = total_length - sum(splits[:-1])\n",
    "\n",
    "    # 按照分割点分割数组\n",
    "    split_arrays = []\n",
    "    start = 0\n",
    "    for split in splits:\n",
    "        split_arrays.append(arr[start:start + split])\n",
    "        start += split\n",
    "\n",
    "    return split_arrays\n",
    "\n",
    "# 按照batch_size随机划分数据集\n",
    "def split_in_batch(arr, config):\n",
    "    # 划分batch，不足batchsize的直接丢弃\n",
    "    batch_num = arr.shape[0] // config.batch_size \n",
    "    max_length = batch_num * config.batch_size # 最长有效数据长度\n",
    "\n",
    "    # 打乱数据\n",
    "    shuffled_arr = arr[:max_length].copy()\n",
    "    np.random.shuffle(shuffled_arr)\n",
    "\n",
    "    split_arrays = np.array(np.split(shuffled_arr, batch_num))\n",
    "\n",
    "    return split_arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pig dataset is loaded\n",
      "N_max: 151 ,data_type: float32 , batch_size: 111\n",
      "train_data: (36, 111, 151, 5)\n",
      "val_data: (4, 111, 151, 5)\n",
      "test_data: (500, 151, 5)\n"
     ]
    }
   ],
   "source": [
    "config = Config() # 初始化相关配置\n",
    "\n",
    "# 加载数据\n",
    "f_path = config.data_path + config.data_lable + '.npy'\n",
    "f = np.load(f_path)[:config.data_max] \n",
    "\n",
    "# 随机选取数据\n",
    "indices = np.random.choice(f.shape[0], size=config.data_max, replace=False)\n",
    "arr = f[indices]\n",
    "\n",
    "config.N_max = get_max(arr) # 获取最大长度，数据已补全\n",
    "\n",
    "# 划分数据集\n",
    "train_data, val_data, test_data = split_data(arr,[8,1,1])\n",
    "\n",
    "# 划分batch\n",
    "train_data = split_in_batch(train_data, config).astype(np.float32)\n",
    "val_data = split_in_batch(val_data, config).astype(np.float32)\n",
    "test_data = np.array(test_data).astype(np.float32) # test数据不用划分batch\n",
    "\n",
    "\n",
    "# length列表\n",
    "config.lengths = [config.N_max] * config.batch_size \n",
    "\n",
    "print(config.data_lable, 'dataset is loaded')\n",
    "print('N_max:',config.N_max,',data_type:', train_data.dtype,', batch_size:',config.batch_size)\n",
    "print('train_data:',train_data.shape)\n",
    "print('val_data:',val_data.shape)\n",
    "print('test_data:',test_data.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "# 2 \n",
    "\n",
    "class encoderRNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(encoderRNN, self).__init__()\n",
    "        self.lstm = nn.LSTM(5, config.encoder_dim, bidirectional=True) # 双向lstm\n",
    "        self.fc_mu = nn.Linear(config.encoder_dim*2, config.z_dim)\n",
    "        self.fc_sigma = nn.Linear(config.encoder_dim*2, config.z_dim)\n",
    "\n",
    "\n",
    "    def forward(self, config, input):\n",
    "        h0 = torch.zeros(2, config.batch_size, config.encoder_dim).to(config.device)\n",
    "        c0 = torch.zeros(2, config.batch_size, config.encoder_dim).to(config.device)\n",
    "        hidden_cell = (h0, c0)\n",
    "\n",
    "        outputs, (hidden, cell) = self.lstm(input, hidden_cell)\n",
    "\n",
    "        # 完成编码，调整数据形状\n",
    "        # (2, batch_size, hidden_size) -> (batch_size, 2*hidden_size)\n",
    "        hidden_forward, hidden_backward = torch.split(hidden, 1, 0)\n",
    "        hidden_cat = torch.cat([hidden_forward.squeeze(0), hidden_backward.squeeze(0)], 1)\n",
    "        \n",
    "        # mu部分\n",
    "        mu = self.fc_mu(hidden_cat)\n",
    "\n",
    "        # sigma部分\n",
    "        sigma_hat = self.fc_sigma(hidden_cat)\n",
    "        sigma = torch.exp(sigma_hat / 2.0)\n",
    "\n",
    "        # gaussian noise\n",
    "        N = torch.randn_like(mu)\n",
    "\n",
    "        Z = mu + sigma * N\n",
    "\n",
    "\n",
    "        return Z, mu, sigma_hat\n",
    "\n",
    "# 2\n",
    "class decoderRNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(decoderRNN, self).__init__()\n",
    "        self.N_max = config.N_max\n",
    "        \n",
    "        self.lstm = nn.LSTM(config.z_dim + 5, config.decoder_dim)\n",
    "        self.fc_hc = nn.Linear(config.z_dim, 2 * config.decoder_dim)\n",
    "\n",
    "        # 6M+3\n",
    "        self.fc_output = nn.Linear(config.decoder_dim, 6 * config.M + 3)\n",
    "        # self.fc_q = nn.Linear(config.decoder_dim, 3)\n",
    "        \n",
    "\n",
    "    def forward(self, config, input, z):\n",
    "        h0, c0 = torch.split(torch.tanh(self.fc_hc(z)), config.decoder_dim, 1)\n",
    "        hidden_cell = ((h0.unsqueeze(0).contiguous()), c0.unsqueeze(0).contiguous()) # [batch_size, lstm_size] -> [1, batch_size, lstm_size]\n",
    "\n",
    "        output, (hidden, cell) = self.lstm(input, hidden_cell)\n",
    "\n",
    "        y = self.fc_output(output.view(-1, config.decoder_dim))\n",
    "\n",
    "        # 分割\n",
    "        params = torch.split(y, 6, dim=1)\n",
    "        params_mixture = torch.stack(params[:-1])\n",
    "        params_pen = params[-1]\n",
    "\n",
    "        pi, mu_x, mu_y, sigma_x, sigma_y, rho_xy = torch.split(params_mixture, 1, dim=2)\n",
    "\n",
    "        # pi, mu_x, mu_y, sigma_x, sigma_y, rho_xy = torch.split(self.fc_xy(output), config.M, 2) # 6M\n",
    "        # q = self.fc_q(output) # 3\n",
    "\n",
    "        # 后处理 \n",
    "        # 这些变量的维度？\n",
    "        pi = nn.functional.softmax(pi.transpose(0, 1).squeeze(), dim=-1).view(self.N_max+1, -1, config.M)\n",
    "        sigma_x = torch.exp(sigma_x.transpose(0, 1).squeeze()).view(self.N_max+1, -1, config.M)\n",
    "        sigma_y = torch.exp(sigma_y.transpose(0, 1).squeeze()).view(self.N_max+1, -1, config.M)\n",
    "        rho_xy = torch.tanh(rho_xy.transpose(0, 1).squeeze()).view(self.N_max+1, -1, config.M)\n",
    "        mu_x = mu_x.transpose(0, 1).squeeze().contiguous().view(self.N_max+1, -1, config.M)\n",
    "        mu_y = mu_y.transpose(0, 1).squeeze().contiguous().view(self.N_max+1, -1, config.M)\n",
    "        q = nn.functional.softmax(params_pen, dim=-1).view(self.N_max+1, -1, 3)\n",
    "\n",
    "        return pi, mu_x, mu_y, sigma_x, sigma_y, rho_xy, q, hidden, cell\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 4 训练设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from torch import optim\n",
    "from torch.nn.utils.clip_grad import clip_grad_norm_\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(model, self).__init__()\n",
    "        self.encoder = encoderRNN(config).to(config.device)\n",
    "        self.decoder = decoderRNN(config).to(config.device)\n",
    "\n",
    "        self.encoder_optimizer = optim.Adam(self.encoder.parameters(), lr=config.lr)\n",
    "        self.decoder_optimizer = optim.Adam(self.decoder.parameters(), lr=config.lr)\n",
    "\n",
    "    \n",
    "    # KL Loss\n",
    "    def KL_loss(self, mu, sigma, config):\n",
    "        return -0.5 * torch.sum(1 + sigma - mu.pow(2) - torch.exp(sigma)) / float(config.z_dim * config.batch_size)\n",
    "\n",
    "    # Reconstruction Loss\n",
    "    def RC_loss(self, pi, mu_x, mu_y, sigma_x, sigma_y, rho_xy, q, mask, dx, dy, p, config):\n",
    "        # pdf\n",
    "        z_x = ((dx - mu_x) / sigma_x) ** 2\n",
    "        z_y = ((dy - mu_y) / sigma_y) ** 2\n",
    "        z_xy = (dx - mu_x) * (dy - mu_y) / (sigma_x * sigma_y)\n",
    "        z = z_x + z_y - 2 * rho_xy * z_xy\n",
    "        exp = torch.exp(-z / (2 * (1 - rho_xy ** 2)))\n",
    "        norm = 2 * np.pi * sigma_x * sigma_y * torch.sqrt(1 - rho_xy ** 2)\n",
    "        pdf = torch.nan_to_num(exp / norm, 0.0)\n",
    "\n",
    "        loss_LS = -torch.sum(mask * torch.log(1e-5 + torch.sum(pi * pdf, dim=2))) / float(config.N_max * config.batch_size) # XY\n",
    "        loss_LP = -torch.sum(p * torch.log(q)) / float(config.N_max * config.batch_size) # PPP\n",
    "\n",
    "        return loss_LS + loss_LP\n",
    "\n",
    "    # 处理数据标签（补全，记录有效数据的长度mask机制，分割“笔画、笔状态数据”）\n",
    "    def make_target(self, config, batch):\n",
    "        eos = torch.stack([torch.Tensor([0, 0, 0, 0, 1])] * batch.size()[1]).to(config.device).unsqueeze(0)\n",
    "        batch = torch.cat([batch, eos], 0)\n",
    "        # 记录有效数据的长度mask机制\n",
    "        mask = torch.zeros(config.N_max + 1, batch.shape[1]).to(config.device) \n",
    "        for idx, length in enumerate(config.lengths):\n",
    "            mask[:length, idx] = 1 # 真实有效数据才能进行后续计算\n",
    "\n",
    "        # 分割“笔画、笔状态数据”\n",
    "        dx = torch.stack([batch.data[:, :, 0]] * config.M, 2)\n",
    "        dy = torch.stack([batch.data[:, :, 1]] * config.M, 2)\n",
    "        p1 = batch.data[:, :, 2]\n",
    "        p2 = batch.data[:, :, 3]\n",
    "        p3 = batch.data[:, :, 4]\n",
    "        p = torch.stack([p1, p2, p3], dim=2)\n",
    "\n",
    "        return mask, dx, dy, p\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    # 储存模型（解码编码分开保存）\n",
    "    def save(self, config, model, epoch):\n",
    "        if config.continue_train:\n",
    "            epochs = epoch + config.last_train_epoch\n",
    "        else:\n",
    "            epochs = epoch\n",
    "        \n",
    "        # save encoder and decoder\n",
    "        torch.save(model.encoder.state_dict(), f\"./saved_model/trained_SRNN_{config.data_lable}_epoch{epochs}_encoder.pth\")\n",
    "        torch.save(model.decoder.state_dict(), f\"./saved_model/trained_SRNN_{config.data_lable}_epoch{epochs}_decoder.pth\")\n",
    "\n",
    "\n",
    "    def train(self, config, train_data, val_data):\n",
    "        train_loss_epoch_history = []\n",
    "        train_LKL_epoch_history = []\n",
    "        train_LR_epoch_history = []\n",
    "\n",
    "        val_loss_epoch_history = []\n",
    "        val_LKL_epoch_history = []\n",
    "        val_LR_epoch_history = []\n",
    "\n",
    "\n",
    "        best_val_loss = 100000000 # 初始化一个较大的值\n",
    "        best_model = None\n",
    "        \n",
    "        train_data = torch.from_numpy(train_data).to(config.device)\n",
    "        val_data = torch.from_numpy(val_data).to(config.device)\n",
    "\n",
    "\n",
    "        for epoch in range(config.epoch):\n",
    "            print(f'Start training, now epoch {config.last_train_epoch + epoch+1}/{config.last_train_epoch + config.epoch}')\n",
    "            train_loss_history = []\n",
    "            train_LKL_history = []\n",
    "            train_LR_history = []\n",
    "\n",
    "            val_loss_history = []\n",
    "            val_LKL_history = []\n",
    "            val_LR_history = []\n",
    "\n",
    "\n",
    "            # 训练阶段\n",
    "            self.encoder.train()\n",
    "            self.decoder.train()\n",
    "\n",
    "            for train_batch in tqdm(train_data): \n",
    "                # encoder\n",
    "                train_batch = train_batch.permute(1,0,2)\n",
    "                train_z, train_mu, train_sigma = self.encoder(config, train_batch)\n",
    "\n",
    "                # decoder\n",
    "                # S0数据准备\n",
    "                s0 = torch.stack([torch.Tensor([0, 0, 1, 0, 0])] * config.batch_size).to(config.device).unsqueeze(0) # [1, batch_size, 5]\n",
    "\n",
    "                train_batch_init = torch.cat([s0, train_batch], dim = 0) # 引入s0的数据,[N_max+1, batch_size, 5]\n",
    "                train_z_stack = torch.stack([train_z] * (config.N_max + 1)) # [N_max+1, batch_size, z_dim]\n",
    "                train_inputs = torch.cat([train_batch_init, train_z_stack], dim=2) # [N_max+1, batch_size, 5+z_dim]\n",
    "\n",
    "                train_pi, train_mu_x, train_mu_y, train_sigma_x, train_sigma_y, train_rho_xy, train_q, _, _ = self.decoder(config, train_inputs, train_z)\n",
    "\n",
    "                # 计算损失\n",
    "                train_mask, train_dx, train_dy, train_p = self.make_target(config, train_batch) # y_true数据\n",
    "             \n",
    "                rc_loss = self.RC_loss(train_pi, train_mu_x, train_mu_y, train_sigma_x, train_sigma_y, train_rho_xy, train_q, train_mask, train_dx, train_dy, train_p, config)\n",
    "                kl_loss = self.KL_loss(train_mu, train_sigma, config)\n",
    "                train_loss = rc_loss + config.W_kl *kl_loss \n",
    "\n",
    "                # 记录训练损失\n",
    "                train_loss_history.append(train_loss.item())\n",
    "                train_LKL_history.append(kl_loss.item())\n",
    "                train_LR_history.append(rc_loss.item())\n",
    "\n",
    "\n",
    "                # 反向传播\n",
    "                self.encoder_optimizer.zero_grad()\n",
    "                self.decoder_optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                \n",
    "                clip_grad_norm_(self.encoder.parameters(), config.grad_clip)\n",
    "                clip_grad_norm_(self.decoder.parameters(), config.grad_clip)\n",
    "                self.encoder_optimizer.step()\n",
    "                self.decoder_optimizer.step()\n",
    "\n",
    "\n",
    "            # 验证val阶段\n",
    "            self.encoder.eval()\n",
    "            self.decoder.eval()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                for val_batch in val_data:\n",
    "                    # encoder\n",
    "                    val_batch = val_batch.permute(1,0,2)\n",
    "                    val_z, val_mu, val_sigma = self.encoder(config, val_batch)\n",
    "\n",
    "                    # decoder\n",
    "\n",
    "                    val_s0 = torch.stack([torch.Tensor([0, 0, 1, 0, 0])] * config.batch_size).to(config.device).unsqueeze(0) # [1, batch_size, 5]\n",
    "\n",
    "                    val_batch_init = torch.cat([val_s0, val_batch], dim = 0)\n",
    "                    val_z_stack = torch.stack([val_z] * (config.N_max + 1))\n",
    "                    val_inputs = torch.cat([val_batch_init, val_z_stack], dim=2)\n",
    "\n",
    "                    val_pi, val_mu_x, val_mu_y, val_sigma_x, val_sigma_y, val_rho_xy, val_q, _, _ = self.decoder(config, val_inputs, val_z)\n",
    "\n",
    "                    # 计算损失\n",
    "                    val_mask, val_dx, val_dy, val_p = self.make_target(config, val_batch) # y_true数据\n",
    "\n",
    "                    val_rc_loss = self.RC_loss(val_pi, val_mu_x, val_mu_y, val_sigma_x, val_sigma_y, val_rho_xy, val_q, val_mask, val_dx, val_dy, val_p, config)\n",
    "                    val_kl_loss = self.KL_loss(val_mu, val_sigma, config)\n",
    "                    val_loss = val_rc_loss + config.W_kl * val_kl_loss\n",
    "\n",
    "                    # 记录验证损失\n",
    "                    val_loss_history.append(val_loss.item())\n",
    "                    val_LKL_history.append(val_kl_loss.item())\n",
    "                    val_LR_history.append(val_rc_loss.item())\n",
    "\n",
    "                # 每隔一段时间测试一次，绘制图片\n",
    "                if epoch % 10 == 0 and epoch != 0:\n",
    "                    self.test(config, test_data, epoch_now = config.last_train_epoch + epoch + 1)\n",
    "\n",
    "\n",
    "            # 记录每个epoch的损失\n",
    "            train_loss_epoch_history.append(np.mean(train_loss_history).item())\n",
    "            train_LKL_epoch_history.append(np.mean(train_LKL_history).item())\n",
    "            train_LR_epoch_history.append(np.mean(train_LR_history).item())\n",
    "\n",
    "            val_loss_epoch_history.append(np.mean(val_loss_history).item())\n",
    "            val_LKL_epoch_history.append(np.mean(val_LKL_history).item())\n",
    "            val_LR_epoch_history.append(np.mean(val_LR_history).item())\n",
    "\n",
    "\n",
    "            # 保存最优的模型\n",
    "            if epoch > 10 and best_val_loss > min(val_loss_epoch_history):\n",
    "                # 保存模型\n",
    "                self.save(config, self, epoch)\n",
    "                \n",
    "        # end of epoch for\n",
    "\n",
    "        \n",
    "\n",
    "        # 展示训练过程\n",
    "        plt.figure(figsize=(16, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.ylim(0, 10)\n",
    "        plt.plot(train_loss_epoch_history, label='train loss')\n",
    "        plt.plot(train_LR_epoch_history, label='train reconstruction loss', linestyle=':')\n",
    "        plt.plot(val_loss_epoch_history, label='val loss')\n",
    "        plt.plot(val_LR_epoch_history, label='val reconstruction loss', linestyle=':')\n",
    "        plt.title(f'Loss and RCLoss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(train_LKL_epoch_history, label='train KL_loss')\n",
    "        plt.plot(val_LKL_epoch_history, label='val KL_loss')\n",
    "        plt.title(f'KL Loss')\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "\n",
    "    # 使用测试集数据测试模型\n",
    "    def test(self, config, test_data, epoch_now = 0):\n",
    "        batch_size = config.batch_size # 保存原batch_size\n",
    "        self.encoder.eval()\n",
    "        self.decoder.eval()\n",
    "\n",
    "        # 随机抽取其中的一些数据，数据量由config决定\n",
    "        indices = np.random.choice(test_data.shape[0], size=config.gen_num, replace=False)\n",
    "        test_data = test_data[indices]\n",
    "\n",
    "        config.batch_size = config.gen_num\n",
    "        # config.batch_size = 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            test_data = torch.from_numpy(test_data).to(config.device)\n",
    "            self.generate(config, test_data, epoch_now)\n",
    "        \n",
    "        config.batch_size = batch_size # 恢复原batch_size\n",
    "        \n",
    "\n",
    "    # 最终生成样例(有条件)\n",
    "    def generate(self, config, original_data, epoch_now = 0):\n",
    "        # encoder\n",
    "        original_data = original_data.permute(1,0,2)\n",
    "        z, _, _ = self.encoder(config, original_data)\n",
    "        \n",
    "        # decoder\n",
    "        s0 = torch.stack([torch.Tensor([0, 0, 1, 0, 0])] * config.batch_size).to(config.device).unsqueeze(0)\n",
    "        test_batch_init = torch.cat([s0, original_data], dim = 0)\n",
    "        test_z_stack = torch.stack([z] * (config.N_max + 1))\n",
    "        test_inputs = torch.cat([test_batch_init, test_z_stack], dim=2)\n",
    "\n",
    "        test_pi, test_mu_x, test_mu_y, test_sigma_x, test_sigma_y, test_rho_xy, test_q, _, _ = self.decoder(config, test_inputs, z)\n",
    "\n",
    "        # 数据重整\n",
    "        # [gen_num, N_max+1, M]\n",
    "        mu_x = test_mu_x.permute(1,0,2).cpu().numpy()\n",
    "        mu_y = test_mu_y.permute(1,0,2).cpu().numpy()\n",
    "        sigma_x = test_sigma_x.permute(1,0,2).cpu().numpy()\n",
    "        sigma_y = test_sigma_y.permute(1,0,2).cpu().numpy()\n",
    "        rho_xy = test_rho_xy.permute(1,0,2).cpu().numpy()\n",
    "\n",
    "        pred_pi = test_pi.permute(1,0,2).cpu()  # 还要softmax，先不处理成numpy\n",
    "        # [gen_num, N_max+1, 3]\n",
    "        pred_q = test_q.permute(1,0,2).cpu() # 还要softmax，先不处理成numpy\n",
    "\n",
    "        \n",
    "        # xy部分抽样,加权\n",
    "        pi = nn.functional.softmax(pred_pi, dim=2).numpy() # pi已经softmax\n",
    "        x = np.zeros((config.gen_num, config.N_max + 1))\n",
    "        y = np.zeros((config.gen_num, config.N_max + 1))\n",
    "        for i in range(config.M):\n",
    "            mean = np.array([mu_x[:,:,i], mu_y[:,:,i]])\n",
    "\n",
    "            sigma_x[:,:,i] *= np.sqrt(config.temperature)   # 引入温度参数\n",
    "            sigma_y[:,:,i] *= np.sqrt(config.temperature)   # 引入温度参数\n",
    "\n",
    "            sigma = np.array([[sigma_x[:,:,i] ** 2, rho_xy[:,:,i] * sigma_x[:,:,i] * sigma_y[:,:,i]],\n",
    "                      [rho_xy[:,:,i] * sigma_x[:,:,i] * sigma_y[:,:,i], sigma_y[:,:,i] ** 2]])\n",
    "            \n",
    "            # 抽样\n",
    "            samples = np.zeros((config.gen_num, config.N_max + 1, 2))\n",
    "            for j in range(config.gen_num):\n",
    "                for k in range(config.N_max + 1):\n",
    "                    samples[j,k,:] = np.random.multivariate_normal(mean[:,j,k], sigma[:,:,j,k], 1)\n",
    "\n",
    "            x += samples[:,:,0] * pi[:,:,i] # [gen_num, N_max+1]\n",
    "            y += samples[:,:,1] * pi[:,:,i] # [gen_num, N_max+1]\n",
    "\n",
    "        # q部分分类\n",
    "        pred_q /= config.temperature # 引入温度参数\n",
    "        q = nn.Softmax(dim=2)(pred_q)\n",
    "        _, index = torch.max(q, dim=2, keepdim=True) # 最大值进行one-hot编码\n",
    "        q = torch.zeros_like(pred_q).scatter_(2, index, 1.0)\n",
    "        q = q.numpy() # [gen_num, N_max+1, 3]\n",
    "\n",
    "        # 扩展、拼接、得到最终绘画数据\n",
    "        x = np.expand_dims(x, axis=-1) # [gen_num, N_max+1, 1]\n",
    "        y = np.expand_dims(y, axis=-1) # [gen_num, N_max+1, 1]\n",
    "        draw = np.concatenate((x, y, q), axis=-1) # [gen_num, N_max+1, 5]\n",
    "\n",
    "        # 画图\n",
    "        plt.figure(figsize=(16, 4))\n",
    "        colors = ['b', 'g', 'r', 'c', 'm', 'y', 'k']    # 创建一个颜色列表，用于标识不同的点序列\n",
    "        for i in range(config.gen_num):\n",
    "            plt.subplot(2, 5, i+1) \n",
    "            image_data = draw[i]\n",
    "\n",
    "            axis = np.cumsum(image_data[:,:2], axis=0)\n",
    "            track = []\n",
    "            color_index = 0\n",
    "            color = colors[0]\n",
    "\n",
    "            # 具体绘图\n",
    "            for j in range(axis.shape[0]):\n",
    "                track.append([-axis[j][0], -axis[j][1]])\n",
    "\n",
    "                if image_data[j][4] == 1.: # 绘画结束\n",
    "                    plt.plot(*zip(*track), marker='.', color=color)\n",
    "                    track = []\n",
    "                    break\n",
    "\n",
    "                if image_data[j][3] == 1.: # 画笔抬起\n",
    "                    plt.plot(*zip(*track), marker='.', color=color)\n",
    "                    track = []\n",
    "                    color = colors[(color_index)%len(colors)]\n",
    "                    color_index += 1\n",
    "\n",
    "            plt.title(f\"Sample: {i+1}\")\n",
    "            plt.axis('off')\n",
    "\n",
    "        plt.suptitle(f\"Lable: {config.data_lable}. Epochs: {epoch_now}. Temperature: {config.temperature}\")\n",
    "        if config.mode == 'test':\n",
    "            plt.savefig(f'result_test/SRNN_{config.data_lable}_epoch{epoch_now}_temperature{config.temperature}.png')\n",
    "            plt.show()\n",
    "        elif config.mode == 'train':\n",
    "            plt.savefig(f'result_train/SRNN_{config.data_lable}_epoch{epoch_now}_temperature{config.temperature}.png')\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training, now epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/36 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "config.mode = 'train'\n",
    "my_model = model(config)\n",
    "\n",
    "# 一些参数调整，根据实际情况选择\n",
    "config.continue_train = False\n",
    "# config.last_train_epoch = 20\n",
    "if config.continue_train:\n",
    "    my_model.encoder.load_state_dict(torch.load(f\"./saved_model/trained_SRNN_{config.data_lable}_epoch{config.last_train_epoch}_encoder.pth\", map_location=config.device))\n",
    "    my_model.decoder.load_state_dict(torch.load(f\"./saved_model/trained_SRNN_{config.data_lable}_epoch{config.last_train_epoch}_decoder.pth\", map_location=config.device))\n",
    "\n",
    "\n",
    "\n",
    "my_model.train(config, train_data, val_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 展示\n",
    "从刚才指定的数据集中选择图片，进行图片生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './saved_model/trained_SRNN_pig_epoch25_encoder.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m config\u001b[38;5;241m.\u001b[39mtest_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m25\u001b[39m \u001b[38;5;66;03m# 根据实际情况选择\u001b[39;00m\n\u001b[1;32m      3\u001b[0m test_model \u001b[38;5;241m=\u001b[39m model(config)\n\u001b[0;32m----> 5\u001b[0m test_model\u001b[38;5;241m.\u001b[39mencoder\u001b[38;5;241m.\u001b[39mload_state_dict(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./saved_model/trained_SRNN_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_lable\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_epoch\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_epoch\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m_encoder.pth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m      6\u001b[0m test_model\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39mload_state_dict(torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./saved_model/trained_SRNN_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mdata_lable\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_epoch\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mtest_epoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_decoder.pth\u001b[39m\u001b[38;5;124m\"\u001b[39m, map_location\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mdevice))\n\u001b[1;32m      8\u001b[0m test_model\u001b[38;5;241m.\u001b[39mtest(config, test_data, epoch_now \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mtest_epoch)\n",
      "File \u001b[0;32m~/miniconda3/envs/ailab/lib/python3.11/site-packages/torch/serialization.py:986\u001b[0m, in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[0m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m pickle_load_args\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    984\u001b[0m     pickle_load_args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 986\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_file_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_file:\n\u001b[1;32m    987\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_zipfile(opened_file):\n\u001b[1;32m    988\u001b[0m         \u001b[38;5;66;03m# The zipfile reader is going to advance the current file position.\u001b[39;00m\n\u001b[1;32m    989\u001b[0m         \u001b[38;5;66;03m# If we want to actually tail call to torch.jit.load, we need to\u001b[39;00m\n\u001b[1;32m    990\u001b[0m         \u001b[38;5;66;03m# reset back to the original position.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m         orig_position \u001b[38;5;241m=\u001b[39m opened_file\u001b[38;5;241m.\u001b[39mtell()\n",
      "File \u001b[0;32m~/miniconda3/envs/ailab/lib/python3.11/site-packages/torch/serialization.py:435\u001b[0m, in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_open_file_like\u001b[39m(name_or_buffer, mode):\n\u001b[1;32m    434\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m _is_path(name_or_buffer):\n\u001b[0;32m--> 435\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_open_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    436\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    437\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m mode:\n",
      "File \u001b[0;32m~/miniconda3/envs/ailab/lib/python3.11/site-packages/torch/serialization.py:416\u001b[0m, in \u001b[0;36m_open_file.__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, mode):\n\u001b[0;32m--> 416\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './saved_model/trained_SRNN_pig_epoch25_encoder.pth'"
     ]
    }
   ],
   "source": [
    "config.mode = 'test'\n",
    "config.test_epoch = 25 # 根据实际情况选择\n",
    "test_model = model(config)\n",
    "\n",
    "test_model.encoder.load_state_dict(torch.load(f\"./saved_model/trained_SRNN_{config.data_lable}_epoch{config.test_epoch}_encoder.pth\", map_location=config.device))\n",
    "test_model.decoder.load_state_dict(torch.load(f\"./saved_model/trained_SRNN_{config.data_lable}_epoch{config.test_epoch}_decoder.pth\", map_location=config.device))\n",
    "\n",
    "test_model.test(config, test_data, epoch_now = config.test_epoch)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
