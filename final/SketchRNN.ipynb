{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 一些参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class Config():\n",
    "    def __init__(self):\n",
    "        # 数据的部分特征\n",
    "        self.data_lable = 'pig'\n",
    "        self.data_path = './sketch_datas/'\n",
    "        self.data_labels_list = ['ambulance','apple','bear','bicycle','bird','bus','cat','foot','owl','pig']\n",
    "        # self.full_length = 256 # 一条数据的完整长度\n",
    "        self.N_max = 0 # 一条数据的最大长度\n",
    "\n",
    "\n",
    "        # 编码器的参数设置\n",
    "        self.encoder_dim = 256 # encoder的输出维度\n",
    "        self.z_dim = 128 # 中间向量Z的维度\n",
    "\n",
    "        # 解码器的参数设置\n",
    "        self.decoder_dim = 512 # decoder的输出维度\n",
    "        self.M = 20 # GMM的分布数量\n",
    "\n",
    "        # 训练参数\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = 'cuda'\n",
    "        elif torch.backends.mps.is_available():\n",
    "            self.device = 'mps'\n",
    "        else:\n",
    "            self.device = 'cpu'\n",
    "\n",
    "        self.batch_size = 64\n",
    "        self.lr = 0.001\n",
    "        self.epoch = 40\n",
    "        self.W_kl = 0.5 # kl损失的权重\n",
    "        self.temperature = 0.4 # gumbel softmax的温度参数\n",
    "        \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 数据\n",
    "读入数据，并对数据进行预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用（0，0，0，0，1）填充数据到256个\n",
    "from numpy import float32\n",
    "\n",
    "\n",
    "def get_max(arr):\n",
    "    return arr.shape[1]\n",
    "    \n",
    "\n",
    "# 按照7:1:2划分数据集\n",
    "def split_data(arr, ratios):\n",
    "    # 计算分割点\n",
    "    total_length = arr.shape[0]\n",
    "    splits = [int(total_length * ratio / sum(ratios)) for ratio in ratios]\n",
    "    \n",
    "    splits[-1] = total_length - sum(splits[:-1])\n",
    "\n",
    "    # 按照分割点分割数组\n",
    "    split_arrays = []\n",
    "    start = 0\n",
    "    for split in splits:\n",
    "        split_arrays.append(arr[start:start + split])\n",
    "        start += split\n",
    "\n",
    "    return split_arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pig dataset is loaded\n",
      "N_max: 151\n",
      "train_data: (49000, 151, 5)\n",
      "val_data: (7000, 151, 5)\n",
      "test_data: (14000, 151, 5)\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "#1\n",
    "\n",
    "\n",
    "f_path = config.data_path + config.data_lable + '.npy'\n",
    "f = np.load(f_path)\n",
    "config.N_max = get_max(f) # 获取最大长度，数据已补全\n",
    "train_data, val_data, test_data = split_data(f,[7,1,2])\n",
    "\n",
    "\n",
    "print(config.data_lable, 'dataset is loaded')\n",
    "print('N_max:',config.N_max)\n",
    "print('train_data:',train_data.shape)\n",
    "print('val_data:',val_data.shape)\n",
    "print('test_data:',test_data.shape)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 模型搭建"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 9 (1629732296.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[4], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    class decoderRNN(nn.Module):\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block after function definition on line 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 2 \n",
    "#  使用dropout\n",
    "class encoderRNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(encoderRNN, self).__init__()\n",
    "        self.lstm = nn.LSTM(5, config.hidden_size, config.num_layers, dropout=config.dropout_p, bidirectional=True)\n",
    "\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "\n",
    "# 2\n",
    "class decoderRNN(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(decoderRNN, self).__init__()\n",
    "        \n",
    "\n",
    "    \n",
    "    def forward(self, input, hidden):\n",
    "    \n",
    "\n",
    "\n",
    "    # 根据状态（训练or展示结果）决定输出的下一步处理\n",
    "\n",
    "    # split -> 6m+3结果\n",
    "\n",
    "    # GMM模型及其他处理\n",
    "    # 没有管t（随机度）\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 4 训练设定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KL Loss\n",
    "import tqdm\n",
    "\n",
    "\n",
    "def KL_loss(mu, logvar, config):\n",
    "    return -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp()) / float(config.z_dim * config.batch_size)\n",
    "\n",
    "\n",
    "# Reconstruction Loss\n",
    "def R_loss():\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 1\n",
    "class model(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        super(model, self).__init__()\n",
    "        self.encoder = encoderRNN(config)\n",
    "        self.decoder = decoderRNN(config)\n",
    "\n",
    "        self.encoder_optimizer = optim.Adam(self.encoder.parameters(), lr=config.learning_rate)\n",
    "        self.decoder_optimizer = optim.Adam(self.decoder.parameters(), lr=config.learning_rate)\n",
    "\n",
    "\n",
    "    # 储存模型（解码编码分开保存）\n",
    "    def save(self, epoch):\n",
    "        pass\n",
    "\n",
    "    # 读取模型（解码编码分开读取）\n",
    "    def load(self, epoch):\n",
    "        pass\n",
    "\n",
    "\n",
    "    def train(self, config, train_data, val_data):\n",
    "\n",
    "        for epoch in tqdm(range(config.num_epochs)):\n",
    "            # 训练阶段\n",
    "\n",
    "            self.encoder.train()\n",
    "            self.decoder.train()\n",
    "\n",
    "            make_batch()\n",
    "         \n",
    "            # encode\n",
    "\n",
    "\n",
    "            # decode\n",
    "            # S0数据准备\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # 多种损失计算，最后相加\n",
    "            make_target() # 处理数据标签（补全，记录有效数据的长度mask机制，分割“笔画、笔状态数据”）\n",
    "\n",
    "\n",
    "            train_loss = kl_loss + r_loss\n",
    "\n",
    "\n",
    "            train_loss_history.append(train_loss.item())\n",
    "\n",
    "\n",
    "            # 反向传播\n",
    "            self.encoder_optimizer.zero_grad()\n",
    "            self.decoder_optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            nn.utils.clip_grad_norm_(self.encoder.parameters(), config.grad_clip)\n",
    "            nn.utils.clip_grad_norm_(self.decoder.parameters(), config.grad_clip)\n",
    "            self.encoder_optimizer.step()\n",
    "            self.decoder_optimizer.step()\n",
    "\n",
    "\n",
    "            # 验证val阶段\n",
    "            if epoch > config.num_epochs/10:\n",
    "\n",
    "                self.encoder.eval()\n",
    "                self.decoder.eval()\n",
    "\n",
    "                make_batch()\n",
    "\n",
    "                # encode\n",
    "\n",
    "\n",
    "                # decode\n",
    "                # S0数据准备\n",
    "\n",
    "\n",
    "                # 计算损失\n",
    "\n",
    "                val_loss = kl_loss + r_loss\n",
    "\n",
    "\n",
    "                val_loss_history.append(val_loss.item()) # 列表，保存val_loss\n",
    "\n",
    "                # 保存最优的模型\n",
    "                if val_loss < val_loss_history.max():\n",
    "                    self.save(epoch)\n",
    "\n",
    "\n",
    "    # 使用测试集数据测试模型（展示生成结果）\n",
    "    def test(self, config, test_data):\n",
    "        \n",
    "\n",
    "\n",
    "        # 最终生成样例(有条件)\n",
    "        self.generate(config, test_data)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 展示"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ailab",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
