{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务一 复合函数的计算图，计算器雅可比行列式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 numpy实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Computational_Graph:\n",
    "    def __init__(self) -> None:\n",
    "    #初始化x1，x2，x3\n",
    "        self.x1 = 0\n",
    "        self.x2 = 0\n",
    "        self.x3 = 0\n",
    "        #初始化z1，z2，z3，用以存储z1，z2，z3的计算结果\n",
    "        self.z1 = 0\n",
    "        self.z2 = 0\n",
    "        self.z3 = 0\n",
    "        #初始化u1，u2，u3，用以存储u1，u2，u3的计算结果\n",
    "        self.u1 = 0\n",
    "        self.u2 = 0\n",
    "        self.u3 = 0\n",
    "        #初始化v1，v2，v3，用以存储v1，v2，v3的计算结果\n",
    "        self.u1 = 0\n",
    "        self.u2 = 0\n",
    "        self.u3 = 0\n",
    "        #初始化y1，y2，用以存储y1，y2的计算结果\n",
    "        self.y1 = 0\n",
    "        self.y2 = 0 \n",
    "        \n",
    "    def function_z1(self,x1,x2):   \n",
    "        return 2*x1 + x2\n",
    "    def function_z2(self,x1,x3):\n",
    "        return  x1 * 3 * x3   \n",
    "    def function_z3(self,x3):\n",
    "        return  -x3\n",
    "    def function_u1(self,z1):\n",
    "        return  np.sin(self.z1)\n",
    "    def function_u2(self,x3,z2):\n",
    "        return (2 * x3)+z2\n",
    "    def function_u3(self,z1,z3):\n",
    "        return (2 * z1) + z3\n",
    "    def function_v1(self,u1,u3):    \n",
    "        return u1 - u3\n",
    "    def function_v2(self,u2): \n",
    "        return np.sin(-1*u2)      \n",
    "    def function_v3(self,u1,u3):\n",
    "        return u1 * u3\n",
    "    def function_y1(self,v1,v2):\n",
    "        return v1**2 + v2**3\n",
    "    def function_y2(self, v2, v3):\n",
    "        return v2*v3\n",
    "\n",
    "#前向传播\n",
    "    def forward(self,x1,x2,x3):\n",
    "        self.x1 = x1\n",
    "        self.x2 = x2\n",
    "        self.x3 = x3\n",
    "\n",
    "        self.z1 = self.function_z1(self.x1, self.x2)\n",
    "        self.z2 = self.function_z2(self.x1, self.x3)\n",
    "        self.z3 = self.function_z3(self.x3)\n",
    "\n",
    "        self.u1 = self.function_u1(self.z1)\n",
    "        self.u2 = self.function_u2(self.x3, self.z2)\n",
    "        self.u3 = self.function_u3(self.z1, self.z3)\n",
    "\n",
    "        self.v1 = self.function_v1(self.u1, self.u3)\n",
    "        self.v2 = self.function_v2(self.u2)\n",
    "        self.v3 = self.function_v3(self.u1, self.u3)\n",
    "\n",
    "        self.y1 = self.function_y1(self.v1, self.v2)\n",
    "        self.y2 = self.function_y2(self.v2, self.v3)\n",
    "\n",
    "        print(f'y1 = {self.y1}, y2 = {self.y2}')\n",
    "\n",
    "\n",
    "\n",
    "#反向传播\n",
    "    def backward(self):\n",
    "        self.y1_to_v1 = 2 * self.v1\n",
    "        self.y1_to_v2 = 3*(self.v2**2)\n",
    "\n",
    "        self.y2_to_v2 = self.v3\n",
    "        self.y2_to_v3 = self.v2\n",
    "\n",
    "        # backward\n",
    "        self.v1_to_u1 = 1\n",
    "        self.v1_to_u3 = -1\n",
    "\n",
    "        self.v2_to_u2 = -1 * np.cos(-1 * self.u2)\n",
    "        \n",
    "        self.v3_to_u1 = self.u3\n",
    "        self.v3_to_u3 = self.u1\n",
    "\n",
    "\n",
    "        # back\n",
    "        self.u1_to_z1 = np.cos(self.z1)\n",
    "\n",
    "        self.u2_to_x3 = 2 \n",
    "        self.u2_to_z2 = 1\n",
    "\n",
    "        self.u3_to_z1 = 2\n",
    "        self.u3_to_z3 = 1\n",
    "\n",
    "\n",
    "        # back\n",
    "        self.z1_to_x1 = 2\n",
    "        self.z1_to_x2 = 1\n",
    "\n",
    "        self.z2_to_x1 = 3*self.x3\n",
    "        self.z2_to_x3 = 3*self.x1\n",
    "\n",
    "        self.z3_to_x3 = -1\n",
    "\n",
    "        # all \n",
    "        self.y1_to_x1 = self.y1_to_v1 * (self.v1_to_u1*(self.u1_to_z1*self.z1_to_x1) + self.v1_to_u3 * self.u3_to_z1*self.z1_to_x1) + self.y1_to_v2*self.v2_to_u2*self.u2_to_z2*self.z2_to_x1\n",
    "        self.y1_to_x2 = self.y1_to_v1 * (self.v1_to_u1*(self.u1_to_z1*self.z1_to_x2)+ self.v1_to_u3*self.u3_to_z1*self.z1_to_x2)\n",
    "        self.y1_to_x3 = self.y1_to_v1 * (self.v1_to_u3*self.u3_to_z3*self.z3_to_x3) + self.y1_to_v2*self.v2_to_u2*(self.u2_to_x3 +self.u2_to_z2*self.z2_to_x3)\n",
    "\n",
    "        self.y2_to_x1 = self.y2_to_v2 * (self.v2_to_u2 * self.u2_to_z2 * self.z2_to_x1) + self.y2_to_v3* (self.v3_to_u1 *self.u1_to_z1 * self.z1_to_x1 + self.v3_to_u3 *self.u3_to_z1*self.z1_to_x1)\n",
    "        self.y2_to_x2 = self.y2_to_v3 * (self.v3_to_u1 * self.u1_to_z1 *self.z1_to_x2 + self.v3_to_u3*self.u3_to_z1*self.z1_to_x2)\n",
    "        self.y2_to_x3 = self.y2_to_v2 * (self.v2_to_u2 * (self.u2_to_x3+ self.u2_to_z2*self.z2_to_x3))+ self.y2_to_v3*self.v3_to_u3*self.u3_to_z3*self.z3_to_x3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 = 24.490479942112778, y2 = 0.6766170068463221\n",
      "1,1,1 输入的雅可比行列式为 \n",
      " 55.76452114990751 29.056029435566057 -13.630322852587943 \n",
      " -9.55244091025101 -4.475992380884129 -1.1360836488405153\n"
     ]
    }
   ],
   "source": [
    "res = Computational_Graph()\n",
    "res.forward(1,1,1)\n",
    "res.backward()\n",
    "\n",
    "print(f\"1,1,1 输入的雅可比行列式为 \\n {res.y1_to_x1} {res.y1_to_x2} {res.y1_to_x3} \\n {res.y2_to_x1} {res.y2_to_x2} {res.y2_to_x3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 = 64.08711522201764, y2 = -6.078667517564845\n",
      "2,1,3 输入的雅可比行列式为 \n",
      " 45.248661012182595 27.320405391278015 -24.266426122991554 \n",
      " 25.74837188319024 0.061386213049383465 23.646691702463592\n"
     ]
    }
   ],
   "source": [
    "res = Computational_Graph()\n",
    "res.forward(2,1,3)\n",
    "res.backward()\n",
    "\n",
    "print(f\"2,1,3 输入的雅可比行列式为 \\n {res.y1_to_x1} {res.y1_to_x2} {res.y1_to_x3} \\n {res.y2_to_x1} {res.y2_to_x2} {res.y2_to_x3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y1 = 8.170384423581151, y2 = -0.05974457002445096\n",
      "-1,-1,-3 输入的雅可比行列式为 \n",
      " -34.72443898265999 -17.096059449164276 5.658613307843439 \n",
      " -4.530696293583008 -0.37929353394875487 -0.43903810397320575\n"
     ]
    }
   ],
   "source": [
    "res = Computational_Graph()\n",
    "res.forward(-1,-1,-3)\n",
    "res.backward()\n",
    "\n",
    "print(f\"-1,-1,-3 输入的雅可比行列式为 \\n {res.y1_to_x1} {res.y1_to_x2} {res.y1_to_x3} \\n {res.y2_to_x1} {res.y2_to_x2} {res.y2_to_x3}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 pytorch实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "            x1 = x[0]\n",
    "            x2 = x[1]\n",
    "            x3 = x[2]\n",
    "\n",
    "            z1 = 2*x1 + x2\n",
    "            z2= x1 * 3 * x3   \n",
    "            z3 = -x3\n",
    "\n",
    "            u1 =  torch.sin(z1)\n",
    "            u2 = (2 * x3)+z2\n",
    "            u3 =(2 * z1) + z3\n",
    "\n",
    "            v1 = u1 - u3\n",
    "            v2 = torch.sin(-1*u2)      \n",
    "            v3 = u1 * u3\n",
    "\n",
    "            y1 =  v1**2 + v2**3\n",
    "            y2 =  v2*v3\n",
    "\n",
    "            return y1,y2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 55.7645,  29.0560, -13.6303], dtype=torch.float64)\n",
      "tensor([-9.5524, -4.4760, -1.1361], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,1,1], dtype=float, requires_grad=True)\n",
    "model = Net()\n",
    "out_1, out_2 = model(x)\n",
    "\n",
    "out_1.backward()\n",
    "\n",
    "print(x.grad)\n",
    "\n",
    "x = torch.tensor([1,1,1], dtype=float, requires_grad=True)\n",
    "model = Net()\n",
    "out_1, out_2 = model(x)\n",
    "\n",
    "out_2.backward()\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 45.2487,  27.3204, -24.2664], dtype=torch.float64)\n",
      "tensor([25.7484,  0.0614, 23.6467], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([2,1,3], dtype=float, requires_grad=True)\n",
    "model = Net()\n",
    "out_1, out_2 = model(x)\n",
    "\n",
    "out_1.backward()\n",
    "\n",
    "print(x.grad)\n",
    "\n",
    "x = torch.tensor([2,1,3], dtype=float, requires_grad=True)\n",
    "model = Net()\n",
    "out_1, out_2 = model(x)\n",
    "\n",
    "out_2.backward()\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-34.7244, -17.0961,   5.6586], dtype=torch.float64)\n",
      "tensor([-4.5307, -0.3793, -0.4390], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([-1,-1,-3], dtype=float, requires_grad=True)\n",
    "model = Net()\n",
    "out_1, out_2 = model(x)\n",
    "\n",
    "out_1.backward()\n",
    "\n",
    "print(x.grad)\n",
    "\n",
    "x = torch.tensor([-1,-1,-3], dtype=float, requires_grad=True)\n",
    "model = Net()\n",
    "out_1, out_2 = model(x)\n",
    "\n",
    "out_2.backward()\n",
    "\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 任务二 搭建前向神经网络进行分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'W1': array([[-0.01423588,  0.20572217],\n",
      "       [ 0.02832619,  0.1329812 ],\n",
      "       [-0.01546219, -0.00690309],\n",
      "       [ 0.07551805,  0.08256466]]), 'b1': array([[-0.01130692],\n",
      "       [-0.23678376],\n",
      "       [-0.01670494],\n",
      "       [ 0.0685398 ]]), 'W2': array([[ 0.00235001,  0.04562013,  0.02704928, -0.14350081],\n",
      "       [ 0.08828171, -0.05800817, -0.05015653,  0.05909533],\n",
      "       [-0.07316163,  0.02617555, -0.08557956, -0.01875259]]), 'b2': array([[-0.03734863],\n",
      "       [-0.0461971 ],\n",
      "       [-0.08164661]]), 'W3': array([[-0.00451233,  0.01213278,  0.09259528],\n",
      "       [-0.05738197,  0.00527031,  0.22073106],\n",
      "       [ 0.03918219,  0.04827134,  0.0433334 ]]), 'b3': array([[-0.17042917],\n",
      "       [-0.02439081],\n",
      "       [-0.21397038]])}\n"
     ]
    }
   ],
   "source": [
    "# 网络基本结构\n",
    "\n",
    "# nn_architecture = [\n",
    "#     {\"input_dim\": 128, \"output_dim\":256, \"activation\": \"sigmoid\"},\n",
    "#     {\"input_dim\": 256, \"output_dim\": 64, \"activation\": \"sigmoid\"},\n",
    "#     {\"input_dim\": 64, \"output_dim\": 9, \"activation\": \"softmax\"},\n",
    "# ]\n",
    "\n",
    "nn_architecture = [\n",
    "    {\"input_dim\": 2, \"output_dim\":4, \"activation\": \"sigmoid\"},\n",
    "    {\"input_dim\": 4, \"output_dim\": 3, \"activation\": \"sigmoid\"},\n",
    "    {\"input_dim\": 3, \"output_dim\": 3, \"activation\": \"softmax\"},\n",
    "]\n",
    "\n",
    "def init_layers(nn_architecture, seed = 99):\n",
    "    np.random.seed(seed)\n",
    "    number_of_layers = len(nn_architecture)\n",
    "    params_values = {}\n",
    "\n",
    "    for idx, layer in enumerate(nn_architecture):\n",
    "        layer_idx = idx + 1\n",
    "        layer_input_size = layer[\"input_dim\"]\n",
    "        layer_output_size = layer[\"output_dim\"]\n",
    "\n",
    "        params_values['W' + str(layer_idx)] = np.random.randn(\n",
    "            layer_output_size, layer_input_size) * 0.1\n",
    "        params_values['b' + str(layer_idx)] = np.random.randn(\n",
    "            layer_output_size, 1) * 0.1\n",
    "\n",
    "    return params_values\n",
    "\n",
    "print(init_layers(nn_architecture))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))\n",
    "\n",
    "def softmax(Z):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
